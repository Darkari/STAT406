{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LICENSE\n",
    "These notes are released under the \n",
    "\"Creative Commons Attribution-ShareAlike 4.0 International\" license. \n",
    "See the **human-readable version** [here](https://creativecommons.org/licenses/by-sa/4.0/)\n",
    "and the **real thing** [here](https://creativecommons.org/licenses/by-sa/4.0/legalcode). \n",
    "\n",
    "## Lecture slides\n",
    "\n",
    "* The lecture slides will be here. \n",
    "* A reference paper for a formal derivation of AIC: \n",
    "Cavanaugh, J.E. (1997). Unifying the derivations for the Akaike \n",
    "and corrected Akaike information criteria. \n",
    "*Statistics & Probability Letters*, **33**(2), 201-208. \n",
    "[DOI: 10.1016/S0167-7152(96)00128-9](https://doi.org/10.1016/S0167-7152(96)00128-9)\n",
    "\n",
    "\n",
    "## Estimating MSPE with CV when the model was built using the data\n",
    "\n",
    "Last week we learned that one needs to be careful when using cross-validation (in any of its flavours--leave one out, K-fold, etc.) Misuse of cross-validation is, unfortunately,\n",
    "not unusual. For [one example](https://doi.org/10.1073/pnas.102102699) see:\n",
    "\n",
    "> Ambroise, C. and McLachlan, G.J. (2002). Selection bias in gene \n",
    "> extraction on the basis of microarray gene-expression data,\n",
    "> PNAS, 2002, 99 (10), 6562-6566.\n",
    "> DOI: 10.1073/pnas.102102699\n",
    "\n",
    "In particular, for every fold one needs to repeat **everything** that was done with the training set (selecting variables, looking at pairwise correlations, AIC values, etc.)\n",
    "\n",
    "## Correlated covariates\n",
    "\n",
    "Technological advances in recent decades have resulted in data\n",
    "being collected in a fundamentally different manner from the way\n",
    "it was done when most \"classical\" statistical methods were developed\n",
    "(early to mid 1900's).\n",
    "Specifically, it is now not at all uncommon to have data sets with\n",
    "an abundance of potentially useful explanatory variables \n",
    "(for example with more variables than observations). \n",
    "Sometimes the investigators are not sure which of the collected variables\n",
    "can be\n",
    "expected to be useful or meaningful. \n",
    "\n",
    "A consequence of this \"wide net\" data collection strategy is\n",
    "that many of the explanatory variables may be correlated with\n",
    "each other. In what follows we will illustrate some of the\n",
    "problems that this can cause both when training and interpreting\n",
    "models, and also with the resulting predictions.\n",
    "\n",
    "### Variables that were important may suddenly \"dissappear\"\n",
    "\n",
    "Consider the air pollution data set we used \n",
    "earlier, and the \n",
    "**reduced** linear regression model discussed in class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- read.table('../Lecture1/rutgers-lib-30861_CSV-1.csv', header=TRUE, sep=',')\n",
    "reduced <- lm(MORT ~ POOR + HC + NOX + HOUS + NONW, data=x)\n",
    "round( summary(reduced)$coef, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that all coefficients seem to be significant based on\n",
    "the individual tests of hypothesis (with `POOR` and\n",
    "`HOUS` maybe only marginally so). In this sense all 5\n",
    "explanatory varibles in this model appear to be relevant.\n",
    "\n",
    "Now, we fit the **full** model, that is, we include\n",
    "all available explanatory variables in the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full <- lm(MORT ~ ., data=x)\n",
    "round( summary(full)$coef, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the **full** model there \n",
    "are many more parameters that need to be estimated, and while two of\n",
    "them appear to be significantly different from zero (`NONW`\n",
    "and `PREC`), all the others appear to be redundant.\n",
    "In particular, note that the p-values for the individual\n",
    "test of hypotheses for 4 out of the 5\n",
    "regression coefficients for the variables of the **reduced**\n",
    "model have now become not significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round( summary(full)$coef[ names(coef(reduced)), ], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, the coeffficients of \n",
    "explanatory variables that appeared to \n",
    "be relevant in one model may turn\n",
    "to be \"not significant\" when other variables\n",
    "are included. This could pose some challenges \n",
    "for interpreting the estimated parameters of the\n",
    "models.\n",
    "\n",
    "\n",
    "### Why does this happen?\n",
    "\n",
    "Recall that the covariance matrix of the least squares estimator involves the\n",
    "inverse of (X'X), where X' denotes the transpose of the n x p matrix X (that\n",
    "contains each vector of explanatory variables as a row). It is easy to see\n",
    "that if two columns of X are linearly dependent, then X'X will be rank deficient.\n",
    "When two columns of X are \"close\" to being linearly dependent (e.g. their\n",
    "linear corrleation is high), then the matrix X'X will be ill-conditioned, and\n",
    "its inverse will have very large entries. This means that the estimated\n",
    "standard errors of the least squares estimator will be unduly large, resulting\n",
    "in non-significant test of hypotheses for each parameter separately, even if\n",
    "the global test for all of them simultaneously is highly significant.\n",
    "\n",
    "### Why is this a problem if we are interested in prediction?\n",
    "\n",
    "Although in many applications one is interested in interpreting the parameters\n",
    "of the model, even if one is only trying to fit / train a model to do\n",
    "predictions, highly variable parameter estimators will typically result in\n",
    "a noticeable loss of prediction accuracy. This can be easily seen from the\n",
    "bias / variance factorization of the mean squared prediction error (MSPE)\n",
    "mentioned in class. Hence, better predictions can be obtained if one\n",
    "uses less-variable parameter (or regression function) estimators.\n",
    "\n",
    "### What can we do?\n",
    "\n",
    "A commonly used strategy is to remove some explanatory variables from the\n",
    "model, leaving only non-redundant covariates. However, this is easier said than\n",
    "done. You will have seen some strategies in previous Statistics\n",
    "courses (e.g. stepwise variable selection). \n",
    "In coming weeks we will investigate other methods to deal with this problem.\n",
    "\n",
    "\n",
    "## Comparing models -- General strategy\n",
    "\n",
    "Suppose we have a set of competing models from which we want to choose the\n",
    "\"best\" one. In order to properly define our problem we need the following:\n",
    "\n",
    "* a list of models to be considered;\n",
    "* a numerical measure to compare any two models in our list;\n",
    "* a strategy (algorithm, criterion) to navigate the set of models; and\n",
    "* a criterion to stop the search. \n",
    "\n",
    "For example, in stepwise methods the models under consideration in \n",
    "each step are those that differ from the current model only by one\n",
    "coefficient (variable). The numerical measure used to compare models\n",
    "could be AIC, or Mallow's Cp, etc. The strategy is to only consider \n",
    "submodels with one fewer variable than the current one, and we stop\n",
    "if either none of these \"p-1\" submodels is better than the current one, or \n",
    "we reach an empty model. \n",
    "\n",
    "## Comparing models -- What is AIC?\n",
    "\n",
    "One intuitively sensible quantity that can be used to compare models is a\n",
    "distance measuring how \"close\" the distributions implied by these models are from the actual stochastic process generating the data (here \"stochastic process\" refers to the random mechanism that generated the observations). In order to do this we need:\n",
    "\n",
    "a. a distance / metric (or at least a \"quasimetric\") between models; and \n",
    "a. a way of estimating this distance when the \"true\" model is unknown.\n",
    "\n",
    "AIC provides an unbiased estimator of the Kullback-Leibler divergence \n",
    "between the estimated model and the \"true\" one. See the lecture slides\n",
    "for more details. \n",
    "\n",
    "## Using stepwise + AIC to select a model\n",
    "\n",
    "We apply stepwise regression based on AIC to select a linear\n",
    "regression model for the airpollution data. In `R` we can use\n",
    "the function `stepAIC` in package `MASS` to perform a stepwise\n",
    "search, for the synthetic data set discussed in class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "x1 <- rnorm(506)\n",
    "x2 <- rnorm(506, mean=2, sd=1)\n",
    "x3 <- rexp(506, rate=1)\n",
    "x4 <- x2 + rnorm(506, sd=.1)\n",
    "x5 <- x1 + rnorm(506, sd=.1)\n",
    "x6 <- x1 - x2 + rnorm(506, sd=.1)\n",
    "x7 <- x1 + x3 + rnorm(506, sd=.1)\n",
    "y <- x1*3 + x2/3 + rnorm(506, sd=2.2)\n",
    "\n",
    "x <- data.frame(y=y, x1=x1, x2=x2,\n",
    "                x3=x3, x4=x4, x5=x5, x6=x6, x7=x7)\n",
    "\n",
    "library(MASS)\n",
    "null <- lm(y ~ 1, data=x)\n",
    "full <- lm(y ~ ., data=x)\n",
    "st <- stepAIC(null, scope=list(lower=null, upper=full), trace=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see the progression of the search step-by-step, set the\n",
    "argument `trace=TRUE` in the call to `stepAIC` above. \n",
    "The selected model is automatically fit and returned, so that\n",
    "in the code above `st` is an object of class `lm` containing the\n",
    "\"best\" linear regression fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compare the mean squared prediction errors of \n",
    "the **full** model and that selected with **stepwise**. \n",
    "We use 50 runs of 5-fold CV, and obtain\n",
    "the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "echo": "FALSE",
     "fig.height": "5,",
     "fig.width": "5,",
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "k <- 5\n",
    "n <- nrow(x)\n",
    "ii <- (1:n) %% k + 1\n",
    "set.seed(123)\n",
    "N <- 50\n",
    "mspe.t <- mspe.f <- mspe.st <- rep(0, N)\n",
    "for(i in 1:N) {\n",
    "  ii <- sample(ii)\n",
    "  pr.t <- pr.f <- pr.st <- rep(0, n)\n",
    "  for(j in 1:k) {\n",
    "    x0 <- x[ii != j, ]\n",
    "    null0 <- lm(y~1, data=x0)\n",
    "    full0 <- lm(y~., data=x0) # needed for stepwise\n",
    "    true0 <- lm(y~x1 + x2, data=x0)\n",
    "    step.lm0 <- stepAIC(null0, scope=list(lower=null0, upper=full0), trace=FALSE)\n",
    "    pr.st[ ii == j ] <- predict(step.lm0, newdata=x[ii==j,])\n",
    "    pr.f[ ii == j ] <- predict(full0, newdata=x[ii==j,])\n",
    "    pr.t[ ii == j ] <- predict(true0, newdata=x[ii==j,])\n",
    "  }\n",
    "  mspe.st[i] <- mean( (x$y - pr.st)^2 )\n",
    "  mspe.f[i] <- mean( (x$y - pr.f)^2 )\n",
    "  mspe.t[i] <- mean( (x$y - pr.t)^2 )\n",
    "}\n",
    "boxplot(mspe.st, mspe.f, names=c('Stepwise', 'Full'),\n",
    "        col=c('gray60', 'hotpink'), ylab='MSPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that since this is a synthetic data set, we can also\n",
    "estimate the MSPE of the **true** model (could we compute it analytically instead?)\n",
    "and compare it with that of the **full** and **stepwise** models. \n",
    "We obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "echo": "FALSE",
     "fig.height": "5,",
     "fig.width": "5,",
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "boxplot(mspe.t, mspe.st, mspe.f, names=c('True', 'Stepwise', 'Full'),\n",
    "        col=c('tomato', 'gray60', 'hotpink'), ylab='MSPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stepwise applied to the \"air pollution\" data \n",
    "\n",
    "We now use stepwise on the air pollution data to select a model, and\n",
    "estimate its MSPE using 5-fold CV. We compare the predictions of \n",
    "this model with that of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "airp <- read.table('../lecture1/rutgers-lib-30861_CSV-1.csv', header=TRUE, sep=',')\n",
    "null <- lm(MORT ~ 1, data=airp)\n",
    "full <- lm(MORT ~ ., data=airp)\n",
    "( tmp.st <- stepAIC(full, scope=list(lower=null), trace=FALSE) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "fig.height": "5",
     "fig.width": "5,",
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "k <- 5\n",
    "n <- nrow(airp)\n",
    "ii <- (1:n) %% k + 1\n",
    "set.seed(123)\n",
    "N <- 50\n",
    "mspe.f <- mspe.st <- rep(0, N)\n",
    "for(i in 1:N) {\n",
    "  ii <- sample(ii)\n",
    "  pr.f <- pr.st <- rep(0, n)\n",
    "  for(j in 1:k) {\n",
    "    x0 <- airp[ii != j, ]\n",
    "    null0 <- lm(MORT ~ 1, data=x0)\n",
    "    full0 <- lm(MORT ~ ., data=x0) # needed for stepwise\n",
    "    step.lm0 <- stepAIC(null0, scope=list(lower=null0, upper=full0), trace=FALSE)\n",
    "    pr.st[ ii == j ] <- predict(step.lm0, newdata=airp[ii==j,])\n",
    "    pr.f[ ii == j ] <- predict(full0, newdata=airp[ii==j,])\n",
    "  }\n",
    "  mspe.st[i] <- mean( (airp$MORT - pr.st)^2 )\n",
    "  mspe.f[i] <- mean( (airp$MORT - pr.f)^2 )\n",
    "}\n",
    "boxplot(mspe.st, mspe.f, names=c('Stepwise', 'Full'),\n",
    "        col=c('gray60', 'hotpink'), ylab='MSPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the package `leaps` to run a more thorough search\n",
    "among all possible subsets. We do this with the air pollution data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(leaps)\n",
    "a <- leaps(x=as.matrix(airp[, -16]), y=airp$MORT, int=TRUE, method='Cp', nbest=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the call above we asked `leaps` to compute the 10 best models\n",
    "of each size, according to Mallow's Cp criterion. We can look at\n",
    "the returned object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now find the best model (based on Mallow's Cp), and \n",
    "fit the corresponding model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j0 <- which.min(a$Cp)\n",
    "( m1 <- lm(MORT ~ ., data=airp[, c(a$which[j0,], TRUE)]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare which variables are used in this model with those\n",
    "used in the model found with stepwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula(m1)[[3]]\n",
    "formula(tmp.st)[[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is reasonable to ask whether the model found by `leaps` is \n",
    "much better than the one returned by `stepAIC`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractAIC(m1)\n",
    "extractAIC(tmp.st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, what is the MSPE of the model found by `leaps`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "fig.height": "5",
     "fig.width": "5,",
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "# proper way\n",
    "k <- 5\n",
    "n <- nrow(airp)\n",
    "ii <- (1:n) %% k + 1\n",
    "set.seed(123)\n",
    "N <- 50\n",
    "mspe.l <- rep(0, N)\n",
    "for(i in 1:N) {\n",
    "  ii <- sample(ii)\n",
    "  pr.l <- rep(0, n)\n",
    "  for(j in 1:k) {\n",
    "    x0 <- airp[ii != j, ]\n",
    "    tmp.leaps <- leaps(x=as.matrix(x0[, -16]), y=as.vector(x0[,16]), int=TRUE, method='Cp', nbest=10)\n",
    "    j0 <- which.min(tmp.leaps$Cp)\n",
    "    step.leaps <- lm(MORT ~ ., data=x0[, c(tmp.leaps$which[j0,], TRUE)])\n",
    "    pr.l[ ii == j ] <- predict(step.leaps, newdata=airp[ii==j,])\n",
    "  }\n",
    "  mspe.l[i] <- mean( (airp$MORT - pr.l)^2 )\n",
    "}\n",
    "boxplot(mspe.st, mspe.f, mspe.l, names=c('Stepwise', 'Full', 'Leaps'),\n",
    "        col=c('gray60', 'hotpink', 'steelblue'), ylab='MSPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a \"suboptimal\" model (stepwise) seems to be better than\n",
    "the one found with a \"proper\" (exhaustive) search, as that returned by\n",
    "`leaps`. This is intriguing, but we will see the same phenomenon \n",
    "occur in different contexts later in the course. \n",
    "\n",
    "## An example where one may not need to select variables\n",
    "\n",
    "In some cases one may not need to select a subset of explanatory\n",
    "variables, and in fact, doing so may affect negatively the accuracy of\n",
    "the resulting predictions. In what follows we discuss such an example. \n",
    "Consider the credit card data set that contains information\n",
    "on credit card users. The interest is in predicting the \n",
    "balance carried by a client. We first load the data, and to\n",
    "simplify the presentation here we consider only the numerical\n",
    "explanatory variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- read.table('Credit.csv', sep=',', header=TRUE, row.names=1)\n",
    "x <- x[, c(1:6, 11)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 6 available covariates, and a stepwise search selects \n",
    "a model with 5 of them (discarding `Education`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "message": "FALSE",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "null <- lm(Balance ~ 1, data=x)\n",
    "full <- lm(Balance ~ ., data=x)\n",
    "(tmp.st <- stepAIC(null, scope=list(lower=null, upper=full), trace=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is an easy exercise to check that the MSPE of this\n",
    "smaller model is in fact worse than the one for the **full** one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "echo": "FALSE",
     "fig.height": "5,",
     "fig.width": "5,",
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "n <- nrow(x)\n",
    "k <- 5\n",
    "ii <- (1:n) %% k + 1\n",
    "set.seed(123)\n",
    "N <- 100\n",
    "mspe.st <- mspe.f <- rep(0, N)\n",
    "for(i in 1:N) {\n",
    "  ii <- sample(ii)\n",
    "  pr.f <- pr.st <- rep(0, n)\n",
    "  for(j in 1:k) {\n",
    "    null <- lm(Balance ~ 1, data=x[ii != j, ])\n",
    "    full <- lm(Balance ~ ., data=x[ii != j, ])\n",
    "    tmp.st <- stepAIC(null, scope=list(lower=null, upper=full), trace=0)\n",
    "    pr.st[ ii == j ] <- predict(tmp.st, newdata=x[ii==j,])\n",
    "    pr.f[ ii == j ] <- predict(full, newdata=x[ii==j,])\n",
    "  }\n",
    "  mspe.st[i] <- mean( (x$Balance - pr.st)^2 )\n",
    "  mspe.f[i] <- mean( (x$Balance - pr.f)^2 )\n",
    "}\n",
    "boxplot(mspe.st, mspe.f, names=c('Stepwise', 'Full'),\n",
    "        col=c('tomato', 'springgreen'), cex.axis=1.5,\n",
    "        cex.lab=1.5, cex.main=2)\n",
    "mtext(expression(hat(MSPE)), side=2, line=2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Shrinkage methods / Ridge regression  -->\n",
    "\n",
    "<!-- Stepwise methods are highly variable, and thus their predictions may not  -->\n",
    "<!-- be very accurate (high MSPE).  -->\n",
    "<!-- A different way to manage correlated explanatory variables (to \"reduce\" their -->\n",
    "<!-- presence in the model without removing them) is... -->\n",
    "\n",
    "<!-- ### Selecting the amount of shrinkage -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
